# Transformer

- 输入 编码 解码 输出
- 所有的编码器在结构上都是相同的 但是他们没有共享参数，每个解码器都可以分解成为两个子层
- 编码器 可以分为 自注意层+前馈神经网络
- 这层帮助编码器在对每个单词编码时关注输入句子的其他单词。我们将在稍后的文章中更深入地研究自注意力
- 自注意力层的输出会传递到前馈（feed-forward）神经网络中。每个位置的单词对应的前馈神经网络都完全一样（译注：另一种解读就是一层窗口为一个单词的一维卷积神经网络）。



