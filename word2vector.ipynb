{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集行数:\n",
      "    5000 bioCorpus_5000.txt\n",
      "======\n",
      "数据集前10行\n",
      "formate assay in body fluids  application in methanol poisoning.\n",
      "delineation of the intimate details of the backbone conformation of pyridinenucleotide coenzymes in aqueous solution.\n",
      "metal substitutions incarbonic anhydrase  a halide ion probe study.\n",
      "effect of chloroquine on cultured fibroblasts  release of lysosomal hydrolasesand inhibition of their uptake.\n",
      "atomic models for the polypeptide backbones of myohemerythrin and hemerythrin.\n",
      "studies of oxygen binding energy to hemoglobin molecule.\n",
      "maturation of the adrenal medulla--IV\n",
      "effects of morphine.\n",
      "comparison between procaine and isocarboxazid metabolism in vitro by a livermicrosomal amidase-esterase.\n",
      "radiochemical assay of glutathione S-epoxide transferase and its enhancement byphenobarbital in rat liver in vivo.\n"
     ]
    }
   ],
   "source": [
    "!echo '数据集行数:'\n",
    "!wc -l 'bioCorpus_5000.txt'\n",
    "!echo '======'\n",
    "!echo '数据集前10行'\n",
    "!head -10 'bioCorpus_5000.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2vec 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用生成器的方式读取文件里的句子\n",
    "# 适合读取大容量文件，而不用加载到内存\n",
    "class MySentences(object):\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in open(self.fname,'r'):\n",
    "            yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练函数\n",
    "def w2vTrain(f_input, model_output):         \n",
    "    sentences = MySentences(DataDir + f_input)\n",
    "    w2v_model = word2vec.Word2Vec(sentences, \n",
    "                                  min_count = MIN_COUNT, \n",
    "                                  workers = CPU_NUM, \n",
    "                                  size = VEC_SIZE,\n",
    "                                  window = CONTEXT_WINDOW)\n",
    "    w2v_model.save(ModelDir + model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "DataDir = \"./\"\n",
    "ModelDir = \"./ipynb_garbage_files/\"\n",
    "MIN_COUNT = 4\n",
    "CPU_NUM = 2 # 需要预先安装 Cython 以支持并行\n",
    "VEC_SIZE = 20\n",
    "CONTEXT_WINDOW = 5 # 提取目标词上下文距离最长5个词\n",
    "f_input = \"bioCorpus_5000.txt\"\n",
    "model_output = \"test_w2v_model\"\n",
    "w2vTrain(f_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = word2vec.Word2Vec.load(ModelDir+model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-4d5b9b7691d0>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  w2v_model.most_similar('body')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mouse', 0.9994620084762573),\n",
       " ('action', 0.9993744492530823),\n",
       " ('rat', 0.9993621110916138),\n",
       " ('studies', 0.9993410706520081),\n",
       " ('to', 0.9993181228637695),\n",
       " ('A', 0.9992624521255493),\n",
       " ('from', 0.9992518424987793),\n",
       " ('.', 0.9992084503173828),\n",
       " ('as', 0.9991968274116516),\n",
       " ('transport', 0.9991931915283203)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar('body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mxchip/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# 停止词\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "StopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StopWords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新训练\n",
    "# 模型训练函数\n",
    "def w2vTrain_removeStopWords(f_input, model_output):\n",
    "    sentences = list(MySentences(DataDir+f_input))\n",
    "    for idx,sentence in enumerate(sentences):\n",
    "        sentence = [w for w in sentence if w not in StopWords]\n",
    "        sentences[idx]=sentence\n",
    "        w2v_model = word2vec.Word2Vec(sentences, min_count = MIN_COUNT, \n",
    "                                      workers = CPU_NUM, size = VEC_SIZE)\n",
    "        \n",
    "    w2v_model.save(ModelDir+model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vTrain_removeStopWords(f_input, model_output)\n",
    "w2v_model = word2vec.Word2Vec.load(ModelDir+model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.most_similar('body')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
